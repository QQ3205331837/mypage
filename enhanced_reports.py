import re
import requests
from datetime import datetime, timedelta

def enhanced_wechat_reports():
    """å¢å¼ºç‰ˆå¾®ä¿¡ä¸“æ å…¬å¸å‘¨æŠ¥å†…å®¹è·å–å‡½æ•°"""
    try:
        reports = []
        
        # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨wechat_album.htmlæ–‡ä»¶ä¸­çš„æ•°æ®
        try:
            with open('c:\\Users\\zhao\\Desktop\\pyLy\\news_web\\wechat_album.html', 'r', encoding='utf-8') as f:
                local_html = f.read()
            
            print("=== å¾®ä¿¡ä¸“æ HTMLæ–‡ä»¶å†…å®¹ç‰‡æ®µ ===")
            print(local_html[:1000])
            print("==============================")
            
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼ŒåŒæ—¶æå–æ ‡é¢˜ã€é“¾æ¥å’Œåˆ›å»ºæ—¶é—´
            # å…ˆæ‰¾åˆ°æ‰€æœ‰liå…ƒç´ ï¼Œç„¶ååœ¨æ¯ä¸ªliå…ƒç´ ä¸­æå–data-titleã€data-linkå’Œcreate_time
            li_pattern = r'<li[^>]*?class="album__list-item[\s\S]*?</li>'
            li_matches = re.findall(li_pattern, local_html)
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(li_matches)} ä¸ªliå…ƒç´ ")
            
            matches = []
            for li_content in li_matches:
                # åœ¨æ¯ä¸ªliå…ƒç´ ä¸­æå–data-titleã€data-linkå’Œcreate_time
                title_match = re.search(r'data-title="([^"]+)"', li_content)
                link_match = re.search(r'data-link="([^"]+)"', li_content)
                
                # å°è¯•ä»JavaScriptæ•°æ®ä¸­æå–create_time
                create_time_match = None
                
                # æ–¹æ³•1ï¼šä»JavaScriptçš„articleListä¸­æå–
                js_pattern = r"title:\s*'([^']+)'[\s\S]*?create_time:\s*'(\\d+)'"
                js_matches = re.findall(js_pattern, li_content)
                if js_matches:
                    for js_title, js_time in js_matches:
                        if title_match and js_title in title_match.group(1):
                            create_time_match = js_time
                            break
                
                # æ–¹æ³•2ï¼šä»HTMLçš„spanå…ƒç´ ä¸­æå–
                if not create_time_match:
                    time_span_match = re.search(r'<span[^>]*class="js_article_create_time[^>]*>([^<]+)</span>', li_content)
                    if time_span_match:
                        create_time_match = time_span_match.group(1)
                
                if title_match and link_match:
                    matches.append((title_match.group(1), link_match.group(1), create_time_match))
            
            print(f"=== æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç»“æœ ===")
            print(f"æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…é¡¹")
            for i, match in enumerate(matches[:3]):
                print(f"åŒ¹é…é¡¹ {i+1}: æ ‡é¢˜='{match[0]}', é“¾æ¥='{match[1]}', æ—¶é—´æˆ³='{match[2]}'")
            print("========================")
            
            for match in matches:
                if len(match) >= 2:
                    title = str(match[0])  # ç¡®ä¿titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                    link = str(match[1])     # ç¡®ä¿linkæ˜¯å­—ç¬¦ä¸²ç±»å‹
                    create_time = match[2] if len(match) > 2 else None
                    
                    # ä¿®å¤ç¼–ç é—®é¢˜ï¼šå°† \x26amp; å’Œ &amp; æ›¿æ¢ä¸º &
                    title = title.replace('\x26amp;', '&').replace('&amp;', '&')
                    
                    # ç¡®ä¿é“¾æ¥æ˜¯å®Œæ•´çš„URL
                    if link and not link.startswith('http'):
                        link = 'https:' + link if link.startswith('//') else 'https://' + link
                    
                    if title and link and len(title) > 5:
                        # å¤„ç†å‘å¸ƒæ—¥æœŸ
                        if create_time and create_time.isdigit():
                            # ä½¿ç”¨çœŸå®çš„åˆ›å»ºæ—¶é—´æˆ³
                            timestamp = int(create_time)
                            # å°†Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
                            report_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                            print(f"ä½¿ç”¨çœŸå®æ—¥æœŸ: {report_date} (æ—¶é—´æˆ³: {timestamp})")
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°çœŸå®æ—¶é—´æˆ³ï¼Œä½¿ç”¨åˆç†çš„å‘å¸ƒæ—¥æœŸï¼ˆä»æœ€æ–°åˆ°æœ€æ—§ï¼‰
                            base_date = datetime.now()
                            date_offset = len(reports) * 7  # æ¯å‘¨ä¸€ç¯‡
                            report_date = (base_date - timedelta(days=date_offset)).strftime('%Y-%m-%d')
                            print(f"ä½¿ç”¨ä¼°ç®—æ—¥æœŸ: {report_date}")
                        
                        reports.append({
                            "title": title.strip(),
                            "link": link.strip(),
                            "date": report_date,
                            "source": "å…¬å¸å‘¨æŠ¥"
                        })
        except Exception as e:
            print(f"è¯»å–æœ¬åœ°HTMLæ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨åœ¨çº¿æŠ“å–
        if not reports:
            try:
                url = "https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4ODA2ODMzNA==&action=getalbum&album_id=4180740440766726147#wechat_redirect"
                response = requests.get(url, timeout=10)
                html_content = response.text
                
                # ä»åœ¨çº¿HTMLä¸­æå–æ ‡é¢˜ã€é“¾æ¥å’Œåˆ›å»ºæ—¶é—´
                article_patterns = [
                    r'data-title="([^"]+)".*?data-link="([^"]+)".*?create_time:\s*\'(\\d+)\'',
                    r'data-title="([^"]+)"[^>]*data-link="([^"]+)"[^>]*create_time:\s*\'(\\d+)\'',
                ]
                
                for pattern in article_patterns:
                    matches = re.findall(pattern, html_content, re.DOTALL)
                    if matches:
                        for match in matches:
                            if len(match) >= 3:
                                title = str(match[0])  # ç¡®ä¿titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                                link = str(match[1])     # ç¡®ä¿linkæ˜¯å­—ç¬¦ä¸²ç±»å‹
                                create_time = str(match[2])  # åˆ›å»ºæ—¶é—´æˆ³
                                
                                # ä¿®å¤ç¼–ç é—®é¢˜ï¼šå°† \x26amp; å’Œ &amp; æ›¿æ¢ä¸º &
                                title = title.replace('\x26amp;', '&').replace('&amp;', '&')
                                
                                # ç¡®ä¿é“¾æ¥æ˜¯å®Œæ•´çš„URL
                                if link and not link.startswith('http'):
                                    link = 'https:' + link if link.startswith('//') else 'https://' + link
                                
                                if title and link and len(title) > 5:
                                    # å¤„ç†å‘å¸ƒæ—¥æœŸ
                                    if create_time and create_time.isdigit():
                                        # ä½¿ç”¨çœŸå®çš„åˆ›å»ºæ—¶é—´æˆ³
                                        timestamp = int(create_time)
                                        # å°†Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
                                        report_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                                        print(f"ä½¿ç”¨çœŸå®æ—¥æœŸ: {report_date} (æ—¶é—´æˆ³: {timestamp})")
                                    else:
                                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°çœŸå®æ—¶é—´æˆ³ï¼Œä½¿ç”¨åˆç†çš„å‘å¸ƒæ—¥æœŸ
                                        base_date = datetime.now()
                                        date_offset = len(reports) * 7  # æ¯å‘¨ä¸€ç¯‡
                                        report_date = (base_date - timedelta(days=date_offset)).strftime('%Y-%m-%d')
                                        print(f"ä½¿ç”¨ä¼°ç®—æ—¥æœŸ: {report_date}")
                                    
                                    reports.append({
                                        "title": title.strip(),
                                        "link": link.strip(),
                                        "date": report_date,
                                        "source": "å…¬å¸å‘¨æŠ¥"
                                    })
                        
                        if reports:
                            break
            except Exception as e:
                print(f"åœ¨çº¿æŠ“å–å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not reports:
            reports = []
        
        # æŒ‰æ—¥æœŸæ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        reports.sort(key=lambda x: x['date'], reverse=True)
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print("=== å…¬å¸å‘¨æŠ¥æ•°æ®æŠ“å–ç»“æœ ===")
        print(f"æŠ“å–åˆ°çš„å‘¨æŠ¥æ•°é‡: {len(reports)}")
        for i, report in enumerate(reports):
            print(f"å‘¨æŠ¥ {i+1}: {repr(report.get('title', ''))}")
            print(f"     é“¾æ¥: {report.get('link', '')}")
            print(f"     æ—¥æœŸ: {report.get('date', '')}")
        print("==========================")
        
        return reports
        
    except Exception as e:
        print(f"è·å–å¾®ä¿¡ä¸“æ å¤±è´¥: {str(e)}")
        return []  # è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸ä½¿ç”¨ç¤ºä¾‹æ•°æ®

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    result = enhanced_wechat_reports()
    print(f"æœ€ç»ˆç»“æœ: {len(result)} ç¯‡å‘¨æŠ¥")